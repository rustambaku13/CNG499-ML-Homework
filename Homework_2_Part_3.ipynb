{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework 2 Part 3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rustambaku13/ML-Homework-2/blob/master/Homework_2_Part_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e_0YrJmyIsY",
        "colab_type": "code",
        "outputId": "6de334a7-2a97-4668-b597-43f9c30ea618",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import models\n",
        "from keras import layers\n",
        "import keras\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.model_selection import train_test_split,KFold\n",
        "from sklearn.tree import export_graphviz\n",
        "import xgboost as xgb\n",
        "from keras.models import Sequential,Input,Model\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "import cv2\n",
        "import random\n",
        "import matplotlib.image as mpimg\n",
        "import os\n",
        "from sklearn import svm\n",
        "def rgb2gray(rgb):\n",
        "    return np.dot(rgb[...,:3], [0.2125, 0.7154 , 0.0721 ])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Alu42p6byL76",
        "colab_type": "code",
        "outputId": "17b63dfd-63a2-4da3-e42d-1927e528fc28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        }
      },
      "source": [
        "!pip install kaggle\n",
        "!mkdir .kaggle\n",
        "import json\n",
        "import zipfile\n",
        "token = {\"username\":\"rustambaku13\",\"key\":\"c6d933c6a18c4ce55d2a0da20c50daae\"}\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)\n",
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
        "!kaggle config set -n path -v{/content}\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "%pwd\n",
        "!mkdir data\n",
        "!kaggle competitions download -c aerial-cactus-identification -p data \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (3.0.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.3.9)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: text-unidecode==1.2 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.2)\n",
            "mkdir: cannot create directory ‘.kaggle’: File exists\n",
            "- path is now set to: {/content}\n",
            "mkdir: cannot create directory ‘data’: File exists\n",
            "train.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "sample_submission.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "test.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "train.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySWf2bcdySlo",
        "colab_type": "code",
        "outputId": "6542179b-6dff-4290-e562-56fa8321384a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd data\n",
        "zip_ref = zipfile.ZipFile(\"test.zip\", 'r')\n",
        "zip_ref.extractall()\n",
        "zip_ref = zipfile.ZipFile(\"train.zip\", 'r')\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKDK5yeC90vo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ht-uEXEE91ga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = list()\n",
        "y = pd.read_csv(\"train.csv\")\n",
        "for index, row in y.iterrows():\n",
        "  path = \"train/\"+row[\"id\"]\n",
        "  img = plt.imread(path) # and read created path\n",
        "  img = cv2.resize(img,(40,40)) # resize image for lower processing power\n",
        "  x.append(img) # append image to x data\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SiPaZpC-jus",
        "colab_type": "code",
        "outputId": "beab7e17-9f07-476a-88c2-daaab71414e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "source": [
        "plt.subplot(1,1,1)\n",
        "plt.imshow(x[2])\n",
        "y.iloc[2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id            000d1e9a533f62e55c289303b072733d.jpg\n",
              "has_cactus                                       1\n",
              "Name: 2, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/x+RCAgvGinMVAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLF8jNuSAmP3",
        "colab_type": "code",
        "outputId": "259ad861-459a-4377-ccba-13226d655ba6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1969
        }
      },
      "source": [
        "y.drop([\"id\"], axis=1, inplace=True)\n",
        "x = np.array(x)\n",
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>has_cactus</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17470</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17471</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17472</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17473</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17474</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17475</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17476</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17477</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17478</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17479</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17480</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17481</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17482</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17483</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17484</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17485</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17486</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17487</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17488</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17489</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17490</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17491</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17492</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17493</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17494</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17495</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17496</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17497</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17498</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17499</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17500 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       has_cactus\n",
              "0               1\n",
              "1               1\n",
              "2               1\n",
              "3               1\n",
              "4               1\n",
              "5               1\n",
              "6               0\n",
              "7               0\n",
              "8               1\n",
              "9               1\n",
              "10              1\n",
              "11              0\n",
              "12              1\n",
              "13              1\n",
              "14              0\n",
              "15              1\n",
              "16              0\n",
              "17              0\n",
              "18              0\n",
              "19              1\n",
              "20              0\n",
              "21              1\n",
              "22              1\n",
              "23              1\n",
              "24              1\n",
              "25              1\n",
              "26              1\n",
              "27              1\n",
              "28              1\n",
              "29              1\n",
              "...           ...\n",
              "17470           1\n",
              "17471           1\n",
              "17472           1\n",
              "17473           1\n",
              "17474           0\n",
              "17475           0\n",
              "17476           0\n",
              "17477           0\n",
              "17478           1\n",
              "17479           0\n",
              "17480           0\n",
              "17481           1\n",
              "17482           1\n",
              "17483           1\n",
              "17484           0\n",
              "17485           0\n",
              "17486           1\n",
              "17487           1\n",
              "17488           1\n",
              "17489           1\n",
              "17490           1\n",
              "17491           0\n",
              "17492           1\n",
              "17493           1\n",
              "17494           1\n",
              "17495           0\n",
              "17496           1\n",
              "17497           1\n",
              "17498           0\n",
              "17499           1\n",
              "\n",
              "[17500 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBJYUeWJFuPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0Bm2qdkEq-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "fashion_model = Sequential()\n",
        "fashion_model.add(Conv2D(32, kernel_size=(3, 3),activation='linear',input_shape=(40,40,3),padding='same'))\n",
        "fashion_model.add(LeakyReLU(alpha=0.1))\n",
        "fashion_model.add(MaxPooling2D((2, 2),padding='same'))\n",
        "fashion_model.add(Conv2D(64, (3, 3), activation='linear',padding='same'))\n",
        "fashion_model.add(LeakyReLU(alpha=0.1))\n",
        "fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "fashion_model.add(Conv2D(128, (3, 3), activation='linear',padding='same'))\n",
        "fashion_model.add(LeakyReLU(alpha=0.1))                  \n",
        "fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "fashion_model.add(Flatten())\n",
        "fashion_model.add(Dense(128, activation='linear'))\n",
        "fashion_model.add(LeakyReLU(alpha=0.1))                  \n",
        "fashion_model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXDJJe_5FbVg",
        "colab_type": "code",
        "outputId": "b1daa4fd-fab0-4c0f-d944-e4f1d987ef37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "source": [
        "fashion_model.summary()\n",
        "fashion_model.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
        "fashion_train = fashion_model.fit(X_train,y_train, batch_size=128,epochs=5,verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_10 (Conv2D)           (None, 40, 40, 32)        896       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_13 (LeakyReLU)   (None, 40, 40, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 20, 20, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 20, 20, 64)        18496     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_14 (LeakyReLU)   (None, 20, 20, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 10, 10, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 10, 10, 128)       73856     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_15 (LeakyReLU)   (None, 10, 10, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 5, 5, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 3200)              0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 128)               409728    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_16 (LeakyReLU)   (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 503,105\n",
            "Trainable params: 503,105\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "11725/11725 [==============================] - 53s 5ms/step - loss: 3.9607 - acc: 0.7479\n",
            "Epoch 2/5\n",
            "11725/11725 [==============================] - 52s 4ms/step - loss: 3.9485 - acc: 0.7523\n",
            "Epoch 3/5\n",
            "11725/11725 [==============================] - 52s 4ms/step - loss: 3.9485 - acc: 0.7523\n",
            "Epoch 4/5\n",
            "11725/11725 [==============================] - 52s 4ms/step - loss: 3.9485 - acc: 0.7523\n",
            "Epoch 5/5\n",
            "11725/11725 [==============================] - 52s 4ms/step - loss: 3.9485 - acc: 0.7523\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPgkbofoGiRn",
        "colab_type": "code",
        "outputId": "f66a21ac-1c6b-48c0-f2d8-0b147e657d9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "test_eval = fashion_model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', test_eval[0])\n",
        "print('Test accuracy:', test_eval[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 4.0304558996720745\n",
            "Test accuracy: 0.7471861472377529\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gq5y-kRvGAYh",
        "colab_type": "code",
        "outputId": "4298d2a8-d942-4196-f523-5fe58000e15e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "source": [
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "model = ResNet50(weights='imagenet')\n",
        "new_fashion_model = Sequential()\n",
        "new_fashion_model.add(model);\n",
        "new_fashion_model.add(Dense(1, activation='sigmoid'))\n",
        "new_fashion_model.summary()\n",
        "new_fashion_model.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50 (Model)             (None, 1000)              25636712  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 1001      \n",
            "=================================================================\n",
            "Total params: 25,637,713\n",
            "Trainable params: 25,584,593\n",
            "Non-trainable params: 53,120\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9N1KbTkKCSJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = list()\n",
        "y = pd.read_csv(\"train.csv\")\n",
        "for index, row in y.iterrows():\n",
        "  path = \"train/\"+row[\"id\"]\n",
        "  img = plt.imread(path) # and read created path\n",
        "  img = cv2.resize(img,(224,224)) # resize image for lower processing power\n",
        "  x.append(img) # append image to x data\n",
        "\n",
        "y.drop([\"id\"], axis=1, inplace=True)\n",
        "x = np.array(x)\n",
        "y  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0r2wIJfOL2rE",
        "colab_type": "text"
      },
      "source": [
        "**Similar to what has happened in part 2 Of the homework there is clash due to RAM overflow**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUW918EqKxoF",
        "colab_type": "code",
        "outputId": "e68e30fd-d095-4566-9018-99114354e9ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
        "new_fashion_model = new_fashion_model.fit(X_train,y_train, batch_size=128,epochs=5,verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijLRfS3nLMOh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}